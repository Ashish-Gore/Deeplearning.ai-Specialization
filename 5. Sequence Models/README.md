
## Objectives:
  - Learn about recurrent neural networks. This type of model has been proven to perform extremely well on temporal data. It has several variants including LSTMs, GRUs and Bidirectional RNNs.
  - Natural Language Processing & Word Embeddings. Examples of applications are sentiment analysis, named entity recognition and machine translation.
  - Sequence models & Attention mechanism.
  
## Week 1:
  - Building a Recurrent Neural Network - Step by Step - v3
  - Dinosaurus Island -- Character level language model final - v3
  - Improvise a Jazz Solo with an LSTM Network - v3
  
## Week 2:
  - Operations on word vectors - v2
  - Emojify - v2
  
## Week 3:
  - Neural machine translation with attention - v4.ipynb
  - Trigger word detection - v1
  
